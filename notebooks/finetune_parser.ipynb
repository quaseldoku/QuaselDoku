{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d350aea4",
   "metadata": {},
   "source": [
    "# Finetuning des Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678b18c7",
   "metadata": {},
   "source": [
    "Hier soll eine Möglichkeit erarbeitet werden, mit der die HTML-Files am besten extrahiert und bereinigt werden können. Damit soll eine reibungslose Weiterverarbeitung der Texte ermöglicht werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e1ec6a",
   "metadata": {},
   "source": [
    "## Vorüberlegung:\n",
    "\n",
    "Für unser Projekt sind verschiedene Teile des HTML-Files besonders von Bedeutung:\n",
    "\n",
    "- Text: Inhalt der HTML-Seite\n",
    "    - Diese sollte wenn möglich in einzelne Abschnitte gegliedert werden (ermöglicht später die exakte Beantwortung von Fragen)\n",
    "    - Unwichtige Elemente der Seite (wie Menü-Punkte, die auf jeder Seite erscheinen) gilt es zu filtern\n",
    "    - Nichtdarstellbare Zeichen gilt es zu filtern\n",
    "- Überschrift und Unterüberschrift der Paragraphen\n",
    "    - Wenn man im späteren Verlauf auf eine Frage einen Paragrafen referenzieren möchte, ist es wichtig die zum Paragraph gehörende Unterüberschrift und die Verlinkung dahin zu vermerken\n",
    "- HTML-File: Der Link zum verwendeten File sollte als Meta-Data vermerkt werden um später zur Seite navigieren zu können\n",
    "- Links und Bilder: Da wir uns noch nicht im klaren sind ob die Verlinkungen oder dargestellten Bilder für unsere Zwecke nützlich werden könnten, sollten diese zur Vorsicht mit abgespeichert werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa810f3",
   "metadata": {},
   "source": [
    "### Benötigte Pakete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d131563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import glob\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e2be45",
   "metadata": {},
   "source": [
    "### Auslesen von HTML-Elementen\n",
    "\n",
    "Hier wird zunächst nur repräsentativ ein kleiner Teil der Dokumentationsdateien ausgelesen (alle Seiten zum Punkt \"Bedienung\").\n",
    "Die ausgelesenen Daten werden in einem CSV-File gespeichert:\n",
    "\n",
    "|Titel|Unterkapitel|Body|Links|Bilder|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "db1eae4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EasyInsert', 'Tastenkombinationen']\n",
      "['Fernsteuern-von-Produktname', 'Kommandozeile-Batch-Schnittstelle', 'COM-API', 'REST-API', 'Jenkins-Plug-in']\n",
      "['Filter', 'Einfache-Filter', 'Erweiterte-Filter']\n",
      "['Hauptmenu', 'Datei', 'Bearbeiten', 'Ansicht', 'Fenster', 'Optionen', 'Extras', 'Hilfe']\n",
      "['Bedienung']\n",
      "['Automatische-Installation-von-Produktname']\n",
      "['Patches']\n",
      "['Suche']\n",
      "['Tastenkombinationen']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:14: DeprecationWarning: invalid escape sequence '\\W'\n",
      "<>:14: DeprecationWarning: invalid escape sequence '\\W'\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_39852\\3876118319.py:14: DeprecationWarning: invalid escape sequence '\\W'\n",
      "  data = [re.sub('\\W+',' ',soup.h1.get_text()), all_unter, data_text, all_link, all_bild]\n"
     ]
    }
   ],
   "source": [
    "path = 'way/to/files/*.html'\n",
    "files = glob.glob(path)\n",
    "header = ['title','unterkapitel', 'body', 'links','bilder']\n",
    "with open ('test_cleanFiles.csv','w',encoding='utf-8') as save:\n",
    "    writer = csv.writer(save)\n",
    "    writer.writerow(header)\n",
    "    for file in files:\n",
    "        f = open(file, 'r', encoding = \"utf-8\")\n",
    "        soup = BeautifulSoup(f.read(),'html.parser')\n",
    "        data_text = get_body(soup)\n",
    "        all_unter = get_paraName(soup)\n",
    "        all_link = get_link(soup)\n",
    "        all_bild = get_pic(soup)\n",
    "        data = [re.sub('\\W+',' ',soup.h1.get_text()), all_unter, data_text, all_link, all_bild]\n",
    "        #write the data\n",
    "        writer.writerow(data)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2b6dd0",
   "metadata": {},
   "source": [
    "#### Erzeugen des Text-Body Elements\n",
    "\n",
    "Im Div-Block mit der Klasse \"document\" wird der Inhalt der Seite umschlossen (ausgeschlossen das Seiten Menü, Header und Fußzeile)\n",
    "\n",
    "Die Unterteilungen in der Seite erfolgen durch kleinere Div-Blöcke der Klasse \"section\".\n",
    "Die id der Div-Blöcke entspricht der Überschrift (h1 oder h2).\n",
    "Daher werden nun Anhand der Überschriften zunächst die Div-Blöcke gesucht und anschließend die p-Blöcke ausgelesen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a4f514b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_body(soup_elem):\n",
    "    liste_h2 = get_paraName(soup_elem)\n",
    "    clean_para=[]\n",
    "    ordnen = []\n",
    "    \n",
    "    for h2 in liste_h2:\n",
    "        block = soup_elem.find(\"div\",{\"id\":h2.lower()})\n",
    "        for para in block.find_all(\"p\"):\n",
    "            clean_para.append(re.sub(\"\\n\", \" \", para.get_text().strip(), flags=re.M))\n",
    "        ordnen.append((h2, clean_para))\n",
    "    return ordnen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61018b8a",
   "metadata": {},
   "source": [
    "#### Finde Kapitel\n",
    "\n",
    "Es müssen die Kapitelnamen und die Namen der Unterkapitel für jede Datei gesucht werden. Nur so kann später der Inhalt den Überschriften zugeordnet werden.\n",
    "Ein zu der Überschrift gehörender Block, trägt meist den Namen der dazugehördenen Überschrift. Ausnahmen entstehen durch Sonderzeichen.\n",
    "\n",
    "Überlegung: Zur Zeit werden die Namen der Überschriften noch umständlich angepasst, um als id der zugehörigen Div-Blöcke verwendet zu werden. Vielleicht gibt es da einen besseren Work-Around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b5525a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: DeprecationWarning: invalid escape sequence '\\W'\n",
      "<>:7: DeprecationWarning: invalid escape sequence '\\W'\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_39852\\1664730906.py:7: DeprecationWarning: invalid escape sequence '\\W'\n",
      "  sauber = re.sub('\\W+',' ',string)\n"
     ]
    }
   ],
   "source": [
    "def get_paraName(soup_elem):\n",
    "    all_unter = []\n",
    "    heading_tags = [\"h1\", \"h2\"]\n",
    "    for unterkap in soup_elem.find_all(heading_tags):\n",
    "        sauber = re.sub('\\uf0c1','', unterkap.get_text())\n",
    "        string = sauber.replace(\"(\",\"\").replace(\")\",\"\")\n",
    "        sauber = re.sub('\\W+',' ',string)\n",
    "        sauber = re.sub('ü','u',sauber)\n",
    "        sauber = sauber.replace(\"ECU TEST\",\"Produktname\")\n",
    "        all_unter.append(re.sub(' ','-', sauber))\n",
    "    return all_unter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13748fa4",
   "metadata": {},
   "source": [
    "#### Finde Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aed7fa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link(soup_elem):\n",
    "    all_link = []\n",
    "    for link in soup_elem.find_all('a'):\n",
    "        all_link.append(link.get('href'))\n",
    "    return all_link "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d871cd2",
   "metadata": {},
   "source": [
    "#### Finde Bilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fef32ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pic(soup_elem):\n",
    "    all_bild=[]\n",
    "    for bild in soup_elem.find_all('img'):\n",
    "        all_bild.append(bild.get('src'))\n",
    "    return all_bild"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8b7855",
   "metadata": {},
   "source": [
    "### Test-Bereich für einzelnen Funktionen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50644572",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTMLFile = open(\"way/to/Hauptmenue.html\", \"r\", encoding = \"utf-8\")\n",
    "index = HTMLFile.read()\n",
    "S = BeautifulSoup(index,'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46c1b8c",
   "metadata": {},
   "source": [
    "Idee: Alle Paragrafen sind als Div Elemente durch die entsprechende Überschrift (h2) als ID versehen\n",
    "\n",
    "    - Sammle alle h2-Überschriften einer Seite\n",
    "    - Rufe anhand der Überschriften die zugehörigen h2 Divs auf\n",
    "    - extrahiere aus ihnen die p-Blöcke mit dem eigentlichen Inhalte der Seite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bd970bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hauptmenu', 'Datei', 'Bearbeiten', 'Ansicht', 'Fenster', 'Optionen', 'Extras', 'Hilfe']\n"
     ]
    }
   ],
   "source": [
    "liste_h2 = get_paraName(S)\n",
    "print(liste_h2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d025d608",
   "metadata": {},
   "source": [
    "Für jedes Unterkapitel (h2-Überschrift) finde alle P-Blöcke und übernimm den bereinigten Textinhalt in eine Liste. Anschließend ordne diese Liste der entsprechenden Überschrift zu.\n",
    "\n",
    "Aufbau Liste:\n",
    "\n",
    "| Paragrafen   | Inhalt                               |\n",
    "|:----------- | :---------------------------------- |\n",
    "|Überschrift 1 | (Textblock p1), (Textblock p2), .... |\n",
    "|Überschrift 2 | (Textblock p1), (textblock p2), .... |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f47c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_para=[]\n",
    "ordnen = []\n",
    "for h2 in liste_h2:\n",
    "    block = S.find(\"div\",{\"id\":h2.lower()})\n",
    "    for para in block.find_all(\"p\"):\n",
    "        clean_para.append(re.sub(\"\\n\", \" \", para.get_text().strip(), flags=re.M))\n",
    "    ordnen.append((h2, clean_para))\n",
    "print(ordnen[2])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd3d51c",
   "metadata": {},
   "source": [
    "### Problem\n",
    "\n",
    "- Aktuell wird für die Überschrift h1 noch der gesamte Seiteninhalt vermerkt -> man muss also überlegen wie man hier nur den Text bis zur ersten h2-Überschrift extrahieren kann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a52f7da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kedro (quaseldoku)",
   "language": "python",
   "name": "kedro_quaseldoku"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
