{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5911ad1",
   "metadata": {},
   "source": [
    "# Annotation der Test Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3720fac0",
   "metadata": {},
   "source": [
    "Hier sollen zu einigen Passagen / Dokumenten Fragen formuliert und die Antworten dazu annotiert werden. Dabei soll dem SQUAD-Standard gefolgt werden:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac1135f",
   "metadata": {},
   "source": [
    "| ID (int) | context (string) | question (string) | answers (json) |\n",
    "| -: | :- | :- | :- |\n",
    "| 1 | In der letzten Spalte der Signalanbindungstabelle kann eine Standardeinheit für ein generisches Signal angegeben werden. Der Defaulteintrag don’t care bezeichnet die Übernahme der Quelleinheit aus der Aufnahmedatei. | Wo kann die Einheit für genererisches Signal angegeben werden? | { \"text\": [In der letzten Spalte der Signalanbindungstabelle], \"answer_start\": [1] } |\n",
    "| ... | ... | ... | ... | ... |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da3e7f1",
   "metadata": {},
   "source": [
    "Dabei muss sich die ID dem Kontext in der geparsden Doku zuzuordenen sein. Für einen Kontext können mehrere Fragen formuliert werden, auch können mehrere Antworten gegeben werden (Im SQUAD ist der Standard 3, wobei eine Antwort (Antwort-Text und Start-Token) dann wiederholt wird, wenn es im gegeben Kontext nur eine Stelle mit der passenden Antwort gibt, so dass immer drei Antworten pro Fragen annotiert sind). Es sollte ausreichend sein, sich hier auf eine Antwort pro Frage zu beschränken. Für die Ermittlung des Start-Tokens werden Buchstaben, keine Wörter gezählt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60278bd4",
   "metadata": {},
   "source": [
    "Die Idee ist ein zufälliges Dokument auszuwählen und dann eine oder mehrer Fragen zu formulieren. Die Antwort kann dann aus dem Text herausgesucht werden. Über Rückwärtssuche im gegebenen Text / Kontext, kann dann die Antwort im json-Format automatisch erzeugt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4098c093",
   "metadata": {},
   "source": [
    "### Laden der Dokumente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091df2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = catalog.load(\"ecu_test_doku_parsed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fca75fd",
   "metadata": {},
   "source": [
    "### Definieren der nötigen Funtkionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8233a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dbc9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_document():\n",
    "    _id = documents.sample()['Body'].index[0]\n",
    "    context = str(documents.sample()['Body'].iloc[0])\n",
    "    return _id, context\n",
    "\n",
    "def get_start_token_of_string_in_context(context, query_string):\n",
    "    res = context.find(query_string)\n",
    "    if res == -1:\n",
    "        print(\"context does not contain string\")\n",
    "        return {}\n",
    "    else:\n",
    "        return {\"text\": query_string, \"answer_start\": res}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ece140",
   "metadata": {},
   "source": [
    "### Beispiel Anwendung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5785738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define output\n",
    "answers = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4df8d2",
   "metadata": {},
   "source": [
    "#### Wahl eines zufälligen Dokumentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dbd02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_id, context = get_random_document()\n",
    "print(_id)\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a509e561",
   "metadata": {},
   "source": [
    "#### DEBUG: Überschreiben des generierten Kontextes, da html Parser noch nicht geupdatet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786bc8ac",
   "metadata": {},
   "source": [
    "#### Stellen und Beantworte der Frage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b64dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Welche Optionen stehen mir beim Exportieren zur Verfügung?\"\n",
    "answer = \"Beim Export können neben einem Namen, welcher in TEST-GUIDE für das Playbook verwendet werden soll, auch die Workspace Source Informationen hinterlegt werden, um den Workspace auf der Testbench aus einem SCM auszuchecken oder als Artefakt aus TEST-GUIDE zu beziehen. Des Weiteren können Anforderungen (XiLConfigRequirements) an die Testbenches selbst gestellt werden. Diese Anforderungen werden von TEST-GUIDE verwendet, um geeignete Testbenches für die Testausführung auszuwählen. Aktuell wird hier lediglich der XiL-Type unterstützt. Der Katalog an möglichen Anforderungen wird dabei direkt aus TEST-GUIDE bezogen.\"\n",
    "answer_json = get_start_token_of_string_in_context(context, answer)\n",
    "answers.append([_id, context, question, answer])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa06483",
   "metadata": {},
   "source": [
    "### Überführen der Anworten in DataFrame und Speichern als CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbf694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_df = pd.DataFrame(answers)\n",
    "answers_df.columns = ['id', 'context', 'question', 'answers']\n",
    "\n",
    "display(answers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f95b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_df.to_csv(\"../data/03_primary/test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae183411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133ea382",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kedro (quaseldoku)",
   "language": "python",
   "name": "kedro_quaseldoku"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
